// Copyright (c) 2015 Intel Corporation. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#include "realsense/face/win/face_module_object.h"

// This file is auto-generated by face_module.idl
#include "face_module.h" // NOLINT

#include "base/bind.h"
#include "base/logging.h"
#include "base/strings/sys_string_conversions.h"
#include "realsense/common/win/common_utils.h"

namespace {

using NativeModeType = PXCFaceConfiguration::TrackingModeType;
using NativeStrategyType = PXCFaceConfiguration::TrackingStrategyType;
using NativeAlertType = PXCFaceData::AlertData::AlertType;

using JSModeType = realsense::jsapi::face_module::TrackingModeType;
using JSStrategyType = realsense::jsapi::face_module::TrackingStrategyType;
using JSAlertType = realsense::jsapi::face_module::AlertType;

using JSFaceConfigurationData =
    realsense::jsapi::face_module::FaceConfigurationData;
using JSAlertConfiguration =
    realsense::jsapi::face_module::AlertConfiguration;
using JSDetectionConfiguration =
    realsense::jsapi::face_module::DetectionConfiguration;
using JSLandmarksConfiguration =
    realsense::jsapi::face_module::LandmarksConfiguration;
using JSRecognitionConfiguration =
    realsense::jsapi::face_module::RecognitionConfiguration;

NativeModeType TrackingModeJS2Native(JSModeType params_mode) {
  NativeModeType mode;
  if (params_mode == JSModeType::TRACKING_MODE_TYPE_COLOR) {
    mode = NativeModeType::FACE_MODE_COLOR;
  } else if (params_mode == JSModeType::TRACKING_MODE_TYPE_COLOR_DEPTH) {
    mode = NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH;
  } else {
    mode = NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH;
  }

  return mode;
}

NativeStrategyType TrackingStrategyJS2Native(JSStrategyType params_strategy) {
  NativeStrategyType strategy;
  switch (params_strategy) {
    case JSStrategyType::TRACKING_STRATEGY_TYPE_APPEARANCE_TIME:
      strategy = NativeStrategyType::STRATEGY_APPEARANCE_TIME;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_CLOSEST_FARTHEST:
      strategy = NativeStrategyType::STRATEGY_CLOSEST_TO_FARTHEST;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_FARTHEST_CLOSEST:
      strategy = NativeStrategyType::STRATEGY_FARTHEST_TO_CLOSEST;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_LEFT_RIGHT:
      strategy = NativeStrategyType::STRATEGY_LEFT_TO_RIGHT;
      break;
    case JSStrategyType::TRACKING_STRATEGY_TYPE_RIGHT_LEFT:
      strategy = NativeStrategyType::STRATEGY_RIGHT_TO_LEFT;
      break;
    default:
      strategy = NativeStrategyType::STRATEGY_APPEARANCE_TIME;
      break;
  }

  return strategy;
}

JSModeType TrackingModeNative2JS(NativeModeType mode) {
  JSModeType mode_js = JSModeType::TRACKING_MODE_TYPE_NONE;

  if (mode == NativeModeType::FACE_MODE_COLOR) {
    mode_js = JSModeType::TRACKING_MODE_TYPE_COLOR;
  } else if (mode == NativeModeType::FACE_MODE_COLOR_PLUS_DEPTH) {
    mode_js = JSModeType::TRACKING_MODE_TYPE_COLOR_DEPTH;
  }

  return mode_js;
}

JSStrategyType TrackingStrategyNative2JS(NativeStrategyType strategy) {
  JSStrategyType strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_NONE;

  switch (strategy) {
    case NativeStrategyType::STRATEGY_APPEARANCE_TIME:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_APPEARANCE_TIME;
      break;
    case NativeStrategyType::STRATEGY_CLOSEST_TO_FARTHEST:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_CLOSEST_FARTHEST;
      break;
    case NativeStrategyType::STRATEGY_FARTHEST_TO_CLOSEST:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_FARTHEST_CLOSEST;
      break;
    case NativeStrategyType::STRATEGY_LEFT_TO_RIGHT:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_LEFT_RIGHT;
      break;
    case NativeStrategyType::STRATEGY_RIGHT_TO_LEFT:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_RIGHT_LEFT;
      break;
    default:
      strategy_js = JSStrategyType::TRACKING_STRATEGY_TYPE_NONE;
      break;
  }

  return strategy_js;
}

JSAlertType AlertTypeNative2JS(NativeAlertType params_type) {
  JSAlertType type;
  switch (params_type) {
    case NativeAlertType::ALERT_NEW_FACE_DETECTED:
      type = JSAlertType::ALERT_TYPE_NEW_FACE_DETECTED;
      break;
    case JSAlertType::ALERT_TYPE_FACE_OUT_OF_FOV:
      type = JSAlertType::ALERT_TYPE_FACE_OUT_OF_FOV;
      break;
    case JSAlertType::ALERT_TYPE_FACE_BACK_TO_FOV:
      type = JSAlertType::ALERT_TYPE_FACE_BACK_TO_FOV;
      break;
    case JSAlertType::ALERT_TYPE_FACE_OCCLUDED:
      type = JSAlertType::ALERT_TYPE_FACE_OCCLUDED;
      break;
    case JSAlertType::ALERT_TYPE_FACE_NO_LONGER_OCCLUDED:
      type = JSAlertType::ALERT_TYPE_FACE_NO_LONGER_OCCLUDED;
      break;
    case JSAlertType::ALERT_TYPE_FACE_LOST:
      type = JSAlertType::ALERT_TYPE_FACE_LOST;
      break;
    default:
      type = JSAlertType::ALERT_TYPE_NONE;
      break;
  }

  return type;
}

#define SET_ENABLE_DISABLE_ONE_ALERT(_JSFIELD, _NATIVEFIELD) \
    if (config_data.alert->_JSFIELD) { \
      DLOG(INFO) << "ApplyChangesConfig: Enable alert " << #_JSFIELD << ": " \
          << *(config_data.alert->_JSFIELD.get()); \
      if (*(config_data.alert->_JSFIELD.get())) \
        config->EnableAlert(NativeAlertType::_NATIVEFIELD); \
      else  \
        config->DisableAlert(NativeAlertType::_NATIVEFIELD); \
    } \

pxcStatus ApplyChangesConfig(
    PXCFaceConfiguration* config, const JSFaceConfigurationData& config_data) {
  if (config_data.mode != JSModeType::TRACKING_MODE_TYPE_NONE) {
    PXCFaceConfiguration::TrackingModeType mode =
        TrackingModeJS2Native(config_data.mode);
    config->SetTrackingMode(mode);
    DLOG(INFO) << "ApplyChangesConfig: TrackingMode is " << mode;
  }

  if (config_data.strategy != JSStrategyType::TRACKING_STRATEGY_TYPE_NONE) {
    PXCFaceConfiguration::TrackingStrategyType strategy =
        TrackingStrategyJS2Native(config_data.strategy);
    config->strategy = strategy;
    DLOG(INFO) << "ApplyChangesConfig: TrackingStrategy is " << strategy;
  }

  if (config_data.alert) {
    SET_ENABLE_DISABLE_ONE_ALERT(new_face_detected, ALERT_NEW_FACE_DETECTED)
    SET_ENABLE_DISABLE_ONE_ALERT(face_out_of_fov, ALERT_FACE_OUT_OF_FOV)
    SET_ENABLE_DISABLE_ONE_ALERT(face_back_to_fov, ALERT_FACE_BACK_TO_FOV)
    SET_ENABLE_DISABLE_ONE_ALERT(face_occluded, ALERT_FACE_OCCLUDED)
    SET_ENABLE_DISABLE_ONE_ALERT(face_no_longer_occluded,
                                 ALERT_FACE_NO_LONGER_OCCLUDED)
    SET_ENABLE_DISABLE_ONE_ALERT(face_lost, ALERT_FACE_LOST)
  }

  if (config_data.detection) {
    JSDetectionConfiguration* detection = config_data.detection.get();
    if (detection->enable) {
      DLOG(INFO) << "ApplyChangesConfig: Enable detection "
          << *(detection->enable.get());
      config->detection.isEnabled = *(detection->enable.get());
    }
    if (detection->max_faces) {
      DLOG(INFO) << "ApplyChangesConfig: Set detection max faces: "
          << *(detection->max_faces.get());
      config->detection.maxTrackedFaces = *(detection->max_faces.get());
    }
  }

  if (config_data.landmarks) {
    JSLandmarksConfiguration* landmarks = config_data.landmarks.get();
    if (landmarks->enable) {
      DLOG(INFO) << "ApplyChangesConfig: Enable landmarks "
          << *(landmarks->enable.get());
      config->landmarks.isEnabled = *(landmarks->enable.get());
    }
    if (landmarks->max_faces) {
      DLOG(INFO) << "ApplyChangesConfig: Set landmarks max faces: "
          << *(landmarks->max_faces.get());
      config->landmarks.maxTrackedFaces = *(landmarks->max_faces.get());
    }
    // landmarks->num_landmarks setting would take no effect,
    // this field is just for readonly and can not be configured.
  }

  if (config_data.recognition) {
    JSRecognitionConfiguration* recognition = config_data.recognition.get();
    if (recognition->enable) {
      DLOG(INFO) << "ApplyChangesConfig: Enable recognition "
          << *(recognition->enable.get());
      if (*(recognition->enable.get())) {
        config->QueryRecognition()->Enable();
      } else {
        config->QueryRecognition()->Disable();
      }
    }
  }

  return config->ApplyChanges();
}

#define GET_ENABLE_DISABLE_ONE_ALERT(_JSFIELD, _NATIVEFIELD) \
  out_data->alert->_JSFIELD.reset( \
      new bool( \
          config->IsAlertEnabled(NativeAlertType::_NATIVEFIELD) \
              != 0)); \

void RetrieveConfig(
    PXCFaceConfiguration* config, JSFaceConfigurationData* out_data) {
  // Fill JS FaceConfiguration structure out_data.
  out_data->mode = TrackingModeNative2JS(config->GetTrackingMode());
  out_data->strategy = TrackingStrategyNative2JS(config->strategy);

  // AlertConfiguration.
  out_data->alert.reset(new JSAlertConfiguration());
  GET_ENABLE_DISABLE_ONE_ALERT(new_face_detected, ALERT_NEW_FACE_DETECTED)
  GET_ENABLE_DISABLE_ONE_ALERT(face_out_of_fov, ALERT_FACE_OUT_OF_FOV)
  GET_ENABLE_DISABLE_ONE_ALERT(face_back_to_fov, ALERT_FACE_BACK_TO_FOV)
  GET_ENABLE_DISABLE_ONE_ALERT(face_occluded, ALERT_FACE_OCCLUDED)
  GET_ENABLE_DISABLE_ONE_ALERT(face_no_longer_occluded,
                               ALERT_FACE_NO_LONGER_OCCLUDED)
  GET_ENABLE_DISABLE_ONE_ALERT(face_lost, ALERT_FACE_LOST)

  // DetectionConfiguration.
  out_data->detection.reset(new JSDetectionConfiguration());
  JSDetectionConfiguration* detection = out_data->detection.get();
  detection->enable.reset(new bool(config->detection.isEnabled != 0));
  detection->max_faces.reset(new int(config->detection.maxTrackedFaces));

  // LandmarksConfiguration.
  out_data->landmarks.reset(new JSLandmarksConfiguration());
  JSLandmarksConfiguration* landmarks = out_data->landmarks.get();
  landmarks->enable.reset(new bool(config->landmarks.isEnabled != 0));
  landmarks->max_faces.reset(new int(config->landmarks.maxTrackedFaces));
  landmarks->num_landmarks.reset(new int(config->landmarks.numLandmarks));

  // RecognitionConfiguration.
  out_data->recognition.reset(new JSRecognitionConfiguration());
  JSRecognitionConfiguration* recognition = out_data->recognition.get();
  recognition->enable.reset(
      new bool(config->QueryRecognition()->properties.isEnabled != 0));
}

}  // namespace

namespace realsense {
using namespace realsense::common;  // NOLINT
namespace face {

using namespace realsense::jsapi::face_module; // NOLINT
using namespace xwalk::common; // NOLINT

FaceModuleObject::FaceModuleObject()
    : state_(NOT_READY),
      on_processedsample_(false),
      on_error_(false),
      on_alert_(false),
      face_module_thread_("FaceModulePreviewThread"),
      message_loop_(base::MessageLoopProxy::current()),
      session_(NULL),
      sense_manager_(NULL),
      face_output_(NULL),
      face_config_(NULL),
      latest_color_image_(NULL),
      latest_depth_image_(NULL),
      binary_message_size_(0) {
  handler_.Register("setCamera",
                    base::Bind(&FaceModuleObject::OnSetCamera,
                               base::Unretained(this)));
  handler_.Register("start",
                    base::Bind(&FaceModuleObject::OnStart,
                               base::Unretained(this)));
  handler_.Register("stop",
                    base::Bind(&FaceModuleObject::OnStop,
                               base::Unretained(this)));
  handler_.Register("getProcessedSample",
                    base::Bind(&FaceModuleObject::OnGetProcessedSample,
                               base::Unretained(this)));
  handler_.Register("set",
                    base::Bind(&FaceModuleObject::OnSetConf,
                               base::Unretained(this)));
  handler_.Register("getDefaults",
                    base::Bind(&FaceModuleObject::OnGetDefaultsConf,
                               base::Unretained(this)));
  handler_.Register("get",
                    base::Bind(&FaceModuleObject::OnGetConf,
                               base::Unretained(this)));
  handler_.Register("registerUserByFaceID",
                    base::Bind(&FaceModuleObject::OnRegisterUserByFaceID,
                               base::Unretained(this)));
  handler_.Register("unregisterUserByID",
                    base::Bind(&FaceModuleObject::OnUnregisterUserByID,
                               base::Unretained(this)));
}

FaceModuleObject::~FaceModuleObject() {
  OnStop(NULL);
  Destroy();
}


void FaceModuleObject::StartEvent(const std::string& type) {
  if (type == std::string("processedsample")) {
    on_processedsample_ = true;
  } else if (type == std::string("error")) {
    on_error_ = true;
  } else if (type == std::string("alert")) {
    on_alert_ = true;
  }
}

void FaceModuleObject::StopEvent(const std::string& type) {
  if (type == std::string("processedsample")) {
    on_processedsample_ = false;
  } else if (type == std::string("error")) {
    on_error_ = false;
  } else if (type == std::string("alert")) {
    on_alert_ = false;
  }
}

void FaceModuleObject::OnFiredAlert(const PXCFaceData::AlertData *alert) {
  if (!on_alert_) return;

  AlertEventData eventData;
  eventData.type_label = AlertTypeNative2JS(alert->label);
  eventData.time_stamp = alert->timeStamp;
  eventData.face_id = alert->faceId;
  scoped_ptr<base::ListValue> data(new base::ListValue);
  data->Append(eventData.ToValue().release());
  DispatchEvent("alert", data.Pass());
}

void FaceModuleObject::OnSetCamera(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK(!face_module_thread_.IsRunning());

  scoped_ptr<SetCamera::Params> params(
      SetCamera::Params::Create(*info->arguments()));
  if (!params) {
    DispatchErrorEvent("Failed to get setCamera parameters.",
                       ERROR_NAME_INVALIDACCESSERROR);
    return;
  }
  camera_name_ = params->camera;
  DLOG(INFO) << "setCamera name: " << camera_name_;

  // Dispatch "ready" event to indicate ready to start.
  DispatchEvent("ready");
}

void FaceModuleObject::OnStart(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (face_module_thread_.IsRunning()) {
    info->PostResult(
        CreateDOMException("Face module is already started",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;  // Wrong state.
  }

  // In case that camera name has not been set, yet.
  if (camera_name_.empty()) {
    info->PostResult(
        CreateDOMException("Camera has not been set yet",
                           ERROR_NAME_NOTFOUNDERROR));
    return;
  }

  if (!Init()) {
    info->PostResult(
        CreateDOMException("Can't initialize face module",
                           ERROR_NAME_NOTFOUNDERROR));
    return;
  }

  face_module_thread_.Start();

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnStartPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));
}

void FaceModuleObject::OnStop(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_module_thread_.IsRunning()) {
    if (info.get()) {
      info->PostResult(
          CreateDOMException("Face module is not started yet",
                             ERROR_NAME_INVALIDSTATEERROR));
    }
    return;  // Wrong state.
  }

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnStopPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));

  face_module_thread_.Stop();
}

void FaceModuleObject::OnGetProcessedSample(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_module_thread_.IsRunning()) {
    info->PostResult(
        CreateDOMException("Face module is not started yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnGetProcessedSampleOnPipeline,
                 base::Unretained(this),
                 base::Passed(&info)));
}

void FaceModuleObject::OnSetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_module_thread_.IsRunning()) {
    if (!Init()) {
      info->PostResult(
          CreateDOMException("Can't initialize face module",
                             ERROR_NAME_NOTFOUNDERROR));
      return;
    }

    DoSetConf(info.Pass());
  } else {
    // Pipeline is running, do it on face module thread.
    face_module_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceModuleObject::DoSetConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceModuleObject::OnGetDefaultsConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_module_thread_.IsRunning()) {
    if (!Init()) {
      JSFaceConfigurationData config_data;
      info->PostResult(
          CreateDOMException("Can't initialize face module",
                             ERROR_NAME_NOTFOUNDERROR));
      return;
    }

    DoGetDefaultsConf(info.Pass());
  } else {
    // Pipeline is running, do it on face module thread.
    face_module_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceModuleObject::DoGetDefaultsConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceModuleObject::OnGetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is not running, do it on current thread.
  if (!face_module_thread_.IsRunning()) {
    if (!Init()) {
      JSFaceConfigurationData config_data;
      info->PostResult(
          CreateDOMException("Can't initialize face module",
                             ERROR_NAME_NOTFOUNDERROR));
      return;
    }

    DoGetConf(info.Pass());
  } else {
    // Pipeline is running, do it on face module thread.
    face_module_thread_.message_loop()->PostTask(
        FROM_HERE,
        base::Bind(&FaceModuleObject::DoGetConf,
                   base::Unretained(this),
                   base::Passed(&info)));
  }
}

void FaceModuleObject::OnRegisterUserByFaceID(
  scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_module_thread_.IsRunning()) {
    info->PostResult(
        CreateDOMException("Face module is not started yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  scoped_ptr<RegisterUserByFaceID::Params> params(
      RegisterUserByFaceID::Params::Create(*info->arguments()));

  if (!params) {
    info->PostResult(CreateErrorResult(ERROR_CODE_PARAM_UNSUPPORTED));
    return;
  }

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnRegisterUserByFaceIDOnPipeline,
                 base::Unretained(this),
                 params->face_id,
                 base::Passed(&info)));
}

void FaceModuleObject::OnUnregisterUserByID(
  scoped_ptr<XWalkExtensionFunctionInfo> info) {
  if (!face_module_thread_.IsRunning()) {
    info->PostResult(
        CreateDOMException("Face module is not started yet",
                           ERROR_NAME_NOTFOUNDERROR));
    return;
  }

  scoped_ptr<UnregisterUserByID::Params> params(
      UnregisterUserByID::Params::Create(*info->arguments()));

  if (!params) {
    info->PostResult(
        CreateDOMException("There are invalid/unsupported parameters",
                           ERROR_NAME_INVALIDACCESSERROR));
    return;
  }

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnUnregisterUserByIDOnPipeline,
                 base::Unretained(this),
                 params->user_id,
                 base::Passed(&info)));
}

void FaceModuleObject::OnStartPipeline(
  scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());
  DCHECK(state_ == IDLE);

  // Filter the camera.
  // TODO(leonhsl): Seems base::SysUTF8ToWide() can't work well for now,
  // otherwise we can simply call CaptureManager's FilterByDeviceInfo() instead.
  PXCSession::ImplDesc templat = {};
  templat.group = PXCSession::IMPL_GROUP_SENSOR;
  templat.subgroup = PXCSession::IMPL_SUBGROUP_VIDEO_CAPTURE;
  PXCSession::ImplDesc desc;
  PXCCapture* capture;
  int module_index = 0;
  bool found = false;
  while (session_->QueryImpl(&templat, module_index, &desc)
      >= PXC_STATUS_NO_ERROR) {
    if (session_->CreateImpl<PXCCapture>(&desc, &capture) < PXC_STATUS_NO_ERROR)
      continue;

    DLOG(INFO) << "RSSDK capture module: " << desc.friendlyName;

    for (int i = 0; i < capture->QueryDeviceNum(); i++) {
      PXCCapture::DeviceInfo device_info;
      if ((capture->QueryDeviceInfo(i, &device_info)) < PXC_STATUS_NO_ERROR)
        break;

      if (camera_name_ == base::SysWideToUTF8(device_info.name)) {
        found = true;
        sense_manager_->QueryCaptureManager()->FilterByDeviceInfo(&device_info);
        DLOG(INFO) << "Found capture device: "
          << base::SysWideToUTF8(device_info.name) << " "
          << base::SysWideToUTF8(device_info.did);
        break;
      }
    }
    capture->Release();
    if (found)
      break;
    module_index++;
  }

  // Init sense manager.
  pxcStatus status = sense_manager_->Init();
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "Failed to init sense manager: " << status;
    info->PostResult(
        CreateErrorResult(ERROR_CODE_EXEC_FAILED,
            "Failed to init sense manager"));
    ReleasePipelineResources();
    StopFaceModuleThread();
    return;
  }

  if (face_config_->GetTrackingMode() ==
      PXCFaceConfiguration::TrackingModeType::FACE_MODE_COLOR_PLUS_DEPTH) {
    DLOG(INFO) << "Face color_depth tracking mode, set for DS4 device";
    // Quote from C++ SDK FaceTracking sample application.
    PXCCapture::DeviceInfo device_info;
    sense_manager_->QueryCaptureManager()->QueryDevice()
        ->QueryDeviceInfo(&device_info);

    if (device_info.model == PXCCapture::DEVICE_MODEL_DS4) {
      sense_manager_->QueryCaptureManager()->QueryDevice()
          ->SetDSLeftRightExposure(26);
      sense_manager_->QueryCaptureManager()->QueryDevice()
          ->SetDepthConfidenceThreshold(0);
    }
  }

  face_config_->SubscribeAlert(this);
  face_config_->ApplyChanges();

  // Create face module output.
  face_output_ = sense_manager_->QueryFace()->CreateOutput();
  if (!face_output_) {
    DLOG(ERROR) << "Failed to create face output";
    info->PostResult(
        CreateDOMException("Failed to create face output",
                           ERROR_NAME_ABORTERROR));
    ReleasePipelineResources();
    StopFaceModuleThread();
    return;
  }

  // We create color/depth images according current stream profiles.
  CreateProcessedSampleImages();

  DLOG(INFO) << "Start, State transit from IDLE to TRACKING";
  state_ = TRACKING;

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnRunPipeline,
                 base::Unretained(this)));

  info->PostResult(CreateSuccessResult());
}

void FaceModuleObject::OnRunPipeline() {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());
  if (state_ != TRACKING) return;

  pxcStatus status = sense_manager_->AcquireFrame(true);
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "AcquiredFrame failed: " << status;
    if (on_error_) {
      DispatchErrorEvent("Fail to AcquireFrame. Stop.",
                         ERROR_NAME_ABORTERROR);
    }

    ReleasePipelineResources();
    StopFaceModuleThread();
    return;
  }

  face_output_->Update();
  PXCCapture::Sample* face_sample = sense_manager_->QueryFaceSample();
  if (face_sample) {
    if (on_processedsample_) {
      latest_color_image_->CopyImage(face_sample->color);
      if (latest_depth_image_ && face_sample->depth) {
        latest_depth_image_->CopyImage(face_sample->depth);
      }
      DispatchEvent("processedsample");
    }
  } else {
    // face_sample is NULL means face module is paused
    // or error happened. Just ignore and continue next frame.
    DLOG(ERROR) << "QueryFaceSample() returned NULL";
  }

  sense_manager_->ReleaseFrame();

  face_module_thread_.message_loop()->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnRunPipeline,
                 base::Unretained(this)));
}

void FaceModuleObject::OnStopPipeline(
    scoped_ptr<xwalk::common::XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());

  ReleasePipelineResources();

  if (info.get()) {
    info->PostResult(CreateSuccessResult());
  }
}

void FaceModuleObject::OnGetProcessedSampleOnPipeline(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());

  bool fail = false;

  if (state_ != TRACKING) {
    info->PostResult(
        CreateDOMException("Is not started yet, no processed_sample",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  scoped_ptr<GetProcessedSample::Params> params(
      GetProcessedSample::Params::Create(*info->arguments()));
  if (!params) {
    info->PostResult(CreateErrorResult(ERROR_CODE_PARAM_UNSUPPORTED));
    return;
  }
  // Do not transmit color/depth image data by default.
  bool get_color = false;
  bool get_depth = false;
  if (params->get_color) {
    get_color = *(params->get_color.get());
  }
  if (params->get_depth) {
    get_depth = *(params->get_depth.get());
  }

  PXCImage* color = latest_color_image_;
  PXCImage* depth = latest_depth_image_;

  const size_t post_data_size =
      CalculateBinaryMessageSize(get_color, get_depth);
  if (binary_message_size_ < post_data_size) {
    binary_message_.reset(new uint8[post_data_size]);
    binary_message_size_ = post_data_size;
  }

  size_t offset = 0;
  int* int_array = reinterpret_cast<int*>(binary_message_.get());
  // Fill ProcessedSample::color image.
  if (get_color && color) {
    PXCImage::ImageInfo color_info = color->QueryInfo();
    int_array[1] = 1;  // 1 for PixelFormat::PIXEL_FORMAT_RGB32
    int_array[2] = color_info.width;
    int_array[3] = color_info.height;
    offset += 4 * sizeof(int);
    PXCImage::ImageData color_data;
    pxcStatus status = color->AcquireAccess(
        PXCImage::ACCESS_READ, PXCImage::PIXEL_FORMAT_RGB32, &color_data);
    uint8_t* uint8_array =
        reinterpret_cast<uint8_t*>(binary_message_.get() + offset);
    if (status >= PXC_STATUS_NO_ERROR) {
      int k = 0;
      uint8_t* rgb32 = reinterpret_cast<uint8_t*>(color_data.planes[0]);
      for (int y = 0; y < color_info.height; ++y) {
        for (int x = 0; x < color_info.width; ++x) {
          int i = (x + color_info.width * y) * 4;
          uint8_array[k++] = rgb32[i + 2];
          uint8_array[k++] = rgb32[i + 1];
          uint8_array[k++] = rgb32[i];
          uint8_array[k++] = rgb32[i + 3];
        }
      }
      offset += color_info.width * color_info.height * 4;
      color->ReleaseAccess(&color_data);
    } else {
      fail = true;
      DLOG(INFO) << "Failed to access color image data: " << status;
    }
  } else {
    // If no color image to send, set color width and height as 0.
    int_array[1] = 1;
    int_array[2] = 0;
    int_array[3] = 0;
    offset += 4 * sizeof(int);
  }

  int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
  // Fill ProcessedSample::depth image.
  if (!fail) {
    if (get_depth && depth) {
      PXCImage::ImageInfo depth_info = depth->QueryInfo();
      int_array[0] = 2;  // 2 for PixelFormat::PIXEL_FORMAT_DEPTH
      int_array[1] = depth_info.width;
      int_array[2] = depth_info.height;
      offset += 3 * sizeof(int);
      PXCImage::ImageData depth_data;
      pxcStatus status = depth->AcquireAccess(
          PXCImage::ACCESS_READ, PXCImage::PIXEL_FORMAT_DEPTH, &depth_data);
      uint16_t* uint16_array = reinterpret_cast<uint16_t*>(
          binary_message_.get() + offset);
      if (status >= PXC_STATUS_NO_ERROR) {
        int k = 0;
        for (int y = 0; y < depth_info.height; ++y) {
          for (int x = 0; x < depth_info.width; ++x) {
            uint16_t* depth16 =
                reinterpret_cast<uint16_t*>(
                    depth_data.planes[0] + depth_data.pitches[0] * y);
            uint16_array[k++] = depth16[x];
          }
        }
        offset += depth_info.width * depth_info.height * 2;
        depth->ReleaseAccess(&depth_data);
      } else {
        fail = true;
        DLOG(INFO) << "Failed to access depth image data: " << status;
      }
    } else {
      // If no depth image to send, set depth width and height as 0.
      int_array[0] = 2;
      int_array[1] = 0;
      int_array[2] = 0;
      offset += 3 * sizeof(int);
    }
  }

  // Fill ProcessedSample::faces data.
  if (!fail) {
    const int num_of_faces = face_output_->QueryNumberOfDetectedFaces();
    bool detection_enabled = face_config_->detection.isEnabled != 0;
    bool landmarks_enabled = face_config_->landmarks.isEnabled != 0;
    bool recognition_enabled  =
        face_config_->QueryRecognition()->properties.isEnabled != 0;

    int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
    int_array[0] = num_of_faces;
    int_array[1] = detection_enabled ? 1 : 0;
    int_array[2] = landmarks_enabled ? 1 : 0;
    int_array[3] = recognition_enabled ? 1 : 0;
    offset += 4 * sizeof(int);

    for (int i = 0; i < num_of_faces; i++) {
      PXCFaceData::Face* trackedFace = face_output_->QueryFaceByIndex(i);

      // Fill FaceData::faceId
      *(reinterpret_cast<int*>(binary_message_.get() + offset)) =
          trackedFace->QueryUserID();
      offset += sizeof(int);
      DLOG(INFO) << "Tracked face index: " << i
          << " face id: " << trackedFace->QueryUserID();

      if (detection_enabled) {
        const PXCFaceData::DetectionData* detectionData =
            trackedFace->QueryDetection();
        // Fill FaceData::detection data.
        if (detectionData) {
          int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
          PXCRectI32 rectangle;
          if (detectionData->QueryBoundingRect(&rectangle)) {
            DLOG(INFO) << "Tracked face index " << i << ": "
                << rectangle.x << ", " << rectangle.y << ", "
                << rectangle.w << ", " << rectangle.h;
            int_array[0] = rectangle.x;
            int_array[1] = rectangle.y;
            int_array[2] = rectangle.w;
            int_array[3] = rectangle.h;
          }
          offset += 4 * sizeof(int);

          pxcF32 avgDepth;
          if (detectionData->QueryFaceAverageDepth(&avgDepth)) {
            *(reinterpret_cast<float*>(binary_message_.get() + offset)) =
                avgDepth;
          }
          offset += sizeof(float);
        } else {
          // In case of no detection data.
          memset(binary_message_.get() + offset,
                 0,
                 4 * sizeof(int) + sizeof(float));
          offset += (4 * sizeof(int) + sizeof(float));
        }
      }

      if (landmarks_enabled) {
        const PXCFaceData::LandmarksData* landmarkData =
            trackedFace->QueryLandmarks();
        // Fill FaceData::landmarks data.
        if (landmarkData) {
          const int num_of_points = landmarkData->QueryNumPoints();
          DCHECK(num_of_points == face_config_->landmarks.numLandmarks);
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) =
              num_of_points;
          offset += sizeof(int);

          PXCFaceData::LandmarkPoint landmark_point;
          for (int j = 0; j < num_of_points; j++) {
            int_array = reinterpret_cast<int*>(binary_message_.get() + offset);
            landmarkData->QueryPoint(j, &landmark_point);

            DCHECK(landmark_point.source.index == j);
            int_array[0] = landmark_point.source.alias;
            int_array[1] = landmark_point.confidenceImage;
            int_array[2] = landmark_point.confidenceWorld;
            offset += 3 * sizeof(int);

            float* float_array =
                reinterpret_cast<float*>(binary_message_.get() + offset);
            float_array[0] = landmark_point.world.x;
            float_array[1] = landmark_point.world.y;
            float_array[2] = landmark_point.world.z;
            float_array[3] = landmark_point.image.x;
            float_array[4] = landmark_point.image.y;
            offset += 5 * sizeof(float);
          }
        } else {
          // No landmark data for this face.
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) = 0;
          offset += sizeof(int);
        }
      }

      if (recognition_enabled) {
        const PXCFaceData::RecognitionData* recognitionData =
            trackedFace->QueryRecognition();
        // Fill FaceData::recognition data.
        if (recognitionData) {
          const int recognitionID = recognitionData->QueryUserID();
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) =
              recognitionID;
          offset += sizeof(int);
          DLOG(INFO) << "Got recognition id: " << recognitionID;
        } else {
          // No recognition data for this face.
          *(reinterpret_cast<int*>(binary_message_.get() + offset)) = -1;
          offset += sizeof(int);
          DLOG(INFO) << "No recognition data";
        }
      }
    }
  }

  if (fail) {
    info->PostResult(
        CreateDOMException("Failed to prepare processed_sample",
                           ERROR_NAME_ABORTERROR));
  } else {
    DCHECK(offset <= post_data_size);
    scoped_ptr<base::ListValue> result(new base::ListValue());
    result->Append(base::BinaryValue::CreateWithCopiedBuffer(
        reinterpret_cast<const char*>(binary_message_.get()),
        offset));
    info->PostResult(result.Pass());
  }
}

void FaceModuleObject::OnRegisterUserByFaceIDOnPipeline(
    int faceId,
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());

  if (state_ != TRACKING) {
    info->PostResult(
        CreateDOMException("Face module is not started yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  if (face_config_->QueryRecognition()->properties.isEnabled == 0) {
    info->PostResult(
        CreateDOMException("Recognition feature is not enabled yet",
                           ERROR_NAME_ABORTERROR));
    return;
  }

  int registered_id = -1;
  std::string error_msg;
  PXCFaceData::Face* trackedFace = face_output_->QueryFaceByID(faceId);
  if (trackedFace) {
    PXCFaceData::RecognitionData* recognitionData =
        trackedFace->QueryRecognition();
    if (recognitionData) {
      int old_id = recognitionData->QueryUserID();
      registered_id = recognitionData->RegisterUser();
      DLOG(INFO) << "Registered faceId " << faceId <<
          " : (" << old_id << ", " << registered_id << ")";
    } else {
      DLOG(ERROR) << "Failed to get RecognitionData for faceId: " << faceId;
      error_msg = "Failed to get Face Recognition Data";
    }
  } else {
    DLOG(ERROR) << "No FaceData for faceId: " << faceId;
    error_msg = "Failed to find Face Data";
  }

  if (!error_msg.empty()) {
    info->PostResult(
        CreateDOMException(error_msg, ERROR_NAME_ABORTERROR));
  } else {
    info->PostResult(
        RegisterUserByFaceID::Results::Create(registered_id));
  }
}

void FaceModuleObject::OnUnregisterUserByIDOnPipeline(
    int userId,
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());

  if (state_ != TRACKING) {
    info->PostResult(
        CreateDOMException("Face module is not started yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  if (face_config_->QueryRecognition()->properties.isEnabled == 0) {
    info->PostResult(
        CreateDOMException("Recognition feature is not enabled yet",
                           ERROR_NAME_ABORTERROR));
    return;
  }

  std::string error_msg;
  PXCFaceData::RecognitionModuleData* module_data =
      face_output_->QueryRecognitionModule();
  if (module_data) {
    module_data->UnregisterUserByID(userId);
    DLOG(INFO) << "Unregistered recognition id: " << userId;
  } else {
    DLOG(ERROR) << "Failed to get RecognitionModuleData";
    error_msg = "Failed to get Recognition Module Data";
  }

  if (!error_msg.empty()) {
    info->PostResult(
        CreateDOMException(error_msg, ERROR_NAME_ABORTERROR));
  } else {
    info->PostResult(CreateSuccessResult());
  }
}

// May run on face extension thread or face module thread.
void FaceModuleObject::DoSetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        CreateDOMException("Face module is not ready yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  scoped_ptr<Set::Params> params(
      Set::Params::Create(*info->arguments()));
  if (!params) {
    info->PostResult(
        CreateDOMException("There are invalid/unsupported parameters",
                           ERROR_NAME_INVALIDACCESSERROR));
    return;
  }

  // Apply face configurations from JS side.
  pxcStatus status = ApplyChangesConfig(face_config_, params->face_conf);
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "ApplyChangesConfig() failed: " << status;
    info->PostResult(
        CreateDOMException("Failed to set face configuration",
                           ERROR_NAME_ABORTERROR));
    return;
  }
  info->PostResult(CreateSuccessResult());
}

// May run on face extension thread or face module thread.
void FaceModuleObject::DoGetDefaultsConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  JSFaceConfigurationData config_data;

  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        CreateDOMException("Face module is not ready yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  // Call native restoreDefaults().
  face_config_->RestoreDefaults();

  // Get face configurations values.
  RetrieveConfig(face_config_, &config_data);
  // Post FaceConfigurationData to JS side.
  info->PostResult(GetDefaults::Results::Create(config_data));
}

// May run on face extension thread or face module thread.
void FaceModuleObject::DoGetConf(
    scoped_ptr<XWalkExtensionFunctionInfo> info) {
  JSFaceConfigurationData config_data;

  // Pipeline is exiting because of error
  if (state_ == NOT_READY) {
    info->PostResult(
        CreateDOMException("Face module is not ready yet",
                           ERROR_NAME_INVALIDSTATEERROR));
    return;
  }

  // Call native update().
  pxcStatus status = face_config_->Update();
  if (status < PXC_STATUS_NO_ERROR) {
    DLOG(ERROR) << "Face config update() failed: " << status;
    info->PostResult(
        CreateDOMException("Failed to get face configuration",
                           ERROR_NAME_ABORTERROR));
    return;
  }

  // Get face configurations values.
  RetrieveConfig(face_config_, &config_data);
  // Post FaceConfigurationData to JS side.
  info->PostResult(Get::Results::Create(config_data));
}

bool FaceModuleObject::Init() {
  // Assure no race condition between current thread and face_module_thread_
  DCHECK(!face_module_thread_.IsRunning());

  if (state_ != NOT_READY) {
    return true;
  }

  // Create session.
  if (!session_) {
    session_ = PXCSession::CreateInstance();
    if (!session_) {
      DLOG(ERROR) << "Failed to create session";
      return false;
    }
  }

  // Create sense manager.
  if (!sense_manager_) {
    sense_manager_ = session_->CreateSenseManager();
    if (!sense_manager_) {
      DLOG(ERROR) << "Failed to create sense manager";
      return false;
    }
  }

  // Enable face module in sense manager.
  sense_manager_->EnableFace();
  PXCFaceModule* face_module = sense_manager_->QueryFace();
  if (!face_module) {
    DLOG(ERROR) << "Failed to enable face module";
    return false;
  }

  // Create FaceConfiguration instance.
  if (face_config_) {
    face_config_->Release();
  }
  face_config_ = face_module->CreateActiveConfiguration();
  if (!face_config_) {
    DLOG(ERROR) << "Failed to create FaceConfiguration";
    return false;
  }

  // Transit from NOT_READY to IDLE state.
  state_ = IDLE;
  DLOG(INFO) << "State transit from NOT_READY to IDLE";
  return true;
}

void FaceModuleObject::Destroy() {
  // Assure no race condition between current thread and face_module_thread_
  DCHECK(!face_module_thread_.IsRunning());

  if (face_config_) {
    face_config_->Release();
    face_config_ = NULL;
  }

  if (sense_manager_) {
    sense_manager_->Close();
    sense_manager_->Release();
    sense_manager_ = NULL;
  }

  if (session_) {
    session_->Release();
    session_ = NULL;
  }
  DLOG(INFO) << "Destroy, State transit from " << state_ << " to NOT_READY";
  state_ = NOT_READY;
}

void FaceModuleObject::CreateProcessedSampleImages() {
  DCHECK(!latest_color_image_);
  DCHECK(!latest_depth_image_);

  PXCCapture::Device::StreamProfileSet profiles = {};
  sense_manager_->QueryCaptureManager()->QueryDevice()
      ->QueryStreamProfileSet(&profiles);

  // color image.
  if (profiles.color.imageInfo.format) {
    // Only support color stream PIXEL_FORMAT_RGB32.
    if (profiles.color.imageInfo.format == PXCImage::PIXEL_FORMAT_RGB32) {
      DLOG(INFO) << "color.imageInfo: width is "
          << profiles.color.imageInfo.width
          << ", height is " << profiles.color.imageInfo.height
          << ", format is "
          << PXCImage::PixelFormatToString(profiles.color.imageInfo.format);
      PXCImage::ImageInfo image_info = profiles.color.imageInfo;
      image_info.format = PXCImage::PIXEL_FORMAT_RGB32;
      latest_color_image_ = sense_manager_->QuerySession()
          ->CreateImage(&image_info);
    } else {
      DLOG(ERROR) << "Device color stream format is not RGB32: "
          << profiles.color.imageInfo.format;
    }
  } else {
    DLOG(ERROR) << "Device color stream format undefined";
  }
  // depth image.
  if (profiles.depth.imageInfo.format) {
    // Only support depth stream PIXEL_FORMAT_DEPTH.
    if (profiles.depth.imageInfo.format == PXCImage::PIXEL_FORMAT_DEPTH) {
      DLOG(INFO) << "depth.imageInfo: width is "
          << profiles.depth.imageInfo.width
          << ", height is " << profiles.depth.imageInfo.height
          << ", format is "
          << PXCImage::PixelFormatToString(profiles.depth.imageInfo.format);
      PXCImage::ImageInfo image_info = profiles.depth.imageInfo;
      image_info.format = PXCImage::PIXEL_FORMAT_DEPTH;
      latest_depth_image_ = sense_manager_->QuerySession()
          ->CreateImage(&image_info);
    } else {
      DLOG(ERROR) << "Device depth stream format is not DEPTH: "
          << profiles.depth.imageInfo.format;
    }
  } else {
    DLOG(ERROR) << "Device depth stream format undefined";
  }
}

void FaceModuleObject::ReleasePipelineResources() {
  DCHECK_EQ(face_module_thread_.message_loop(), base::MessageLoop::current());

  binary_message_.reset();
  binary_message_size_ = 0;

  if (latest_color_image_) {
    latest_color_image_->Release();
    latest_color_image_ = NULL;
  }
  if (latest_depth_image_) {
    latest_depth_image_->Release();
    latest_depth_image_ = NULL;
  }
  if (face_output_) {
    face_output_->Release();
    face_output_ = NULL;
  }
  if (face_config_) {
    face_config_->UnsubscribeAlert(this);
    face_config_->Release();
    face_config_ = NULL;
  }

  sense_manager_->Close();

  DLOG(INFO) << "Release pipeline, State transit from "
      << state_ << " to NOT_READY";
  state_ = NOT_READY;
}

void FaceModuleObject::StopFaceModuleThread() {
  message_loop_->PostTask(
      FROM_HERE,
      base::Bind(&FaceModuleObject::OnStopFaceModuleThread,
                 base::Unretained(this)));
}

void FaceModuleObject::OnStopFaceModuleThread() {
  if (face_module_thread_.IsRunning()) {
    face_module_thread_.Stop();
  }
}

// binary message: call_id (int32),
// color format (int32), width (int32), height (int32), data (int8 buffer),
// depth format (int32), width (int32), height (int32), data (int16 buffer),
// number of faces (int32),
// detection data available (int32),
// landmark data available (int32),
// recognition data available (int32),
// face data array:
//     array element: faceId (int32),
//                    rect x, y, w, h (int32), avgDepth (float32),
//                    landmark data: number of landmark points (int32),
//                                   landmark point data array:
//                                      array element:
//                                               type (int32),
//                                               image confidence (int32),
//                                               world confidence (int32),
//                                               world point x, y, z (float32),
//                                               image point x, y (float32),
//                    recognition data: recognition ID (int32),
size_t FaceModuleObject::CalculateBinaryMessageSize(
    bool get_color, bool get_depth) {
  const int image_header_size = 3 * sizeof(int);  // format, width, height

  int color_image_size = 0;
  if (get_color && latest_color_image_) {
    PXCImage::ImageInfo color_info = latest_color_image_->QueryInfo();
    color_image_size = color_info.width * color_info.height * 4;
  }

  int depth_image_size = 0;
  if (get_depth && latest_depth_image_) {
    PXCImage::ImageInfo depth_info = latest_depth_image_->QueryInfo();
    depth_image_size = depth_info.width * depth_info.height * 2;
  }

  const int num_of_faces = face_output_->QueryNumberOfDetectedFaces();
  int one_face_size = 0;
  // size for faceId (int32)
  one_face_size += sizeof(int);

  if (face_config_->detection.isEnabled != 0) {
    one_face_size += (4 * sizeof(int) + sizeof(float));
  }
  if (face_config_->landmarks.isEnabled != 0) {
    int landmark_size = 0;
    // size for "number of landmark points"
    landmark_size += sizeof(int);
    // size for "one landmark point data"
    const int landmark_point_size = 3 * sizeof(int) + 5 * sizeof(float);
    landmark_size += face_config_->landmarks.numLandmarks * landmark_point_size;

    one_face_size += landmark_size;
  }

  if (face_config_->QueryRecognition()->properties.isEnabled != 0) {
    one_face_size += sizeof(int);
  }

  const int message_size =
      // call_id
      sizeof(int)
      // color image
      + image_header_size + color_image_size
      // depth image
      + image_header_size + depth_image_size
      // faces
      + 4 * sizeof(int) + num_of_faces * one_face_size;
  return message_size;
}

void FaceModuleObject::DispatchErrorEvent(
    const std::string& message, ErrorName name) {
  DOMException dom_exception;
  dom_exception.message = message;
  dom_exception.name = name;
  scoped_ptr<base::ListValue> data(new base::ListValue);
  data->Append(dom_exception.ToValue().release());
  DispatchEvent("error", data.Pass());
}

}  // namespace face
}  // namespace realsense
